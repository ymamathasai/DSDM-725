{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE888.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymamathasai/DSDM-725/blob/main/DSDM_COVID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbh1Nm2mv_cF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1593d5d9-3f7d-4779-d6c5-d8c1ea7ae593"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gV196flwWAH",
        "outputId": "e08e7092-2e6e-49de-c0eb-709e6a411beb"
      },
      "source": [
        "import os\n",
        "path='/content/drive/My Drive/COVID CLASSIFICATION/CT_COVID/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "    dst =\"covid-\" + str(count) + \".png\"\n",
        "    src =path+ filename \n",
        "    dst =path+ dst \n",
        "        \n",
        "    # rename() function will \n",
        "    # rename all the files \n",
        "    os.rename(src, dst)\n",
        "print(\"Covid Positive cases: \", count)\n",
        "\n",
        "path='/content/drive/My Drive/COVID CLASSIFICATION/CT_NonCOVID/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "    dst =\"noncovid-\" + str(count) + \".png\"\n",
        "    src =path+ filename \n",
        "    dst =path+ dst \n",
        "        \n",
        "    # rename() function will \n",
        "    # rename all the files \n",
        "    os.rename(src, dst)\n",
        "\n",
        "print(\"Covid Negative cases: \", count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covid Positive cases:  357\n",
            "Covid Negative cases:  396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4L_jE7owi9i"
      },
      "source": [
        "base_dir = '/content/drive/My Drive/COVID CLASSIFICATION/covid19_CT'\n",
        "if not os.path.exists(base_dir): os.mkdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdoerskvwoKg"
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "if not os.path.exists(train_dir): os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "if not os.path.exists(validation_dir):os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "if not os.path.exists(test_dir):os.mkdir(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB4PRPsuwsbr"
      },
      "source": [
        "original_dataset_dir_covid = '/content/drive/My Drive/COVID CLASSIFICATION/CT_COVID/'\n",
        "original_dataset_dir_non_covid = '/content/drive/My Drive/COVID CLASSIFICATION/CT_NonCOVID/'\n",
        "\n",
        "import shutil\n",
        "fnames = ['covid-{}.png'.format(i) for i in range(250)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(train_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['covid-{}.png'.format(i) for i in range(250, 300)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(validation_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['covid-{}.png'.format(i) for i in range(300, 348)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(test_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re54BmoRwvzZ"
      },
      "source": [
        "fnames = ['noncovid-{}.png'.format(i) for i in range(250)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(train_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['noncovid-{}.png'.format(i) for i in range(250, 300)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(validation_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['noncovid-{}.png'.format(i) for i in range(300, 348)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(test_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioRUSh9nwyiH"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "IMG_SIZE = 224\n",
        "LR = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeBE7Yidw4KN"
      },
      "source": [
        "def label_img(img):\n",
        "    word_label = img.split('-')[0]\n",
        "    if word_label == 'covid': return 1\n",
        "    elif word_label == 'noncovid': return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_1wMl5xLUa"
      },
      "source": [
        "\n",
        "def createDataSplitSet(datapath):\n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    for img in os.listdir(datapath):\n",
        "        label = label_img(img)\n",
        "        path = os.path.join(datapath, img)\n",
        "        image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
        "        image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        X.append(np.array(image))\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJD_MJhRxOQX",
        "outputId": "85cea07a-7e20-4b6c-f184-be3f8bb066c3"
      },
      "source": [
        "train_X, train_y = createDataSplitSet(train_dir)\n",
        "val_X, val_y = createDataSplitSet(validation_dir)\n",
        "test_X, test_y = createDataSplitSet(test_dir)\n",
        "print(train_X.shape)\n",
        "print(val_X.shape)\n",
        "print(test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 224, 224, 3)\n",
            "(100, 224, 224, 3)\n",
            "(96, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "653O6e9qxgAW"
      },
      "source": [
        "## VGG 16\n",
        "\n",
        "from tensorflow.keras.applications import VGG16,ResNet50\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "img_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQhDbLTCxmub",
        "outputId": "7be91fb4-a3cf-4a89-d40b-e98f39c8cb6d"
      },
      "source": [
        "model = VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=img_input,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "553476096/553467096 [==============================] - 6s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUdBz5t_yLJj",
        "outputId": "75c815bf-67a1-4dc8-ae64-236d78933151"
      },
      "source": [
        "last_layer = model.get_layer('block5_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "x = Dense(128, activation='relu', name='fc1')(x)\n",
        "x = Dense(64, activation='relu', name='fc2')(x)\n",
        "out = Dense(1, activation='sigmoid', name='output')(x)  ## 2 classes\n",
        "model = Model(img_input, out)\n",
        "\n",
        "for layer in model.layers[:-3]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,934,401\n",
            "Trainable params: 3,219,713\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hudg_0k8ymjB"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCmF6hBeyvW7",
        "outputId": "172e7d36-69be-4d59-ae67-f21ad13315ab"
      },
      "source": [
        "history = model.fit(train_X, train_y,\n",
        "                              batch_size=20,\n",
        "                              epochs=100, \n",
        "                              validation_data=(val_X, val_y),)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 41s 289ms/step - loss: 0.6722 - acc: 0.6580 - val_loss: 0.5826 - val_acc: 0.7000\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 7s 281ms/step - loss: 0.3499 - acc: 0.8500 - val_loss: 0.7330 - val_acc: 0.6700\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 0.1885 - acc: 0.9200 - val_loss: 0.5457 - val_acc: 0.7600\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.1336 - acc: 0.9480 - val_loss: 0.5943 - val_acc: 0.7200\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 0.0613 - acc: 0.9920 - val_loss: 0.6795 - val_acc: 0.7500\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0299 - acc: 0.9980 - val_loss: 0.6669 - val_acc: 0.7900\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.6863 - val_acc: 0.7400\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.7832 - val_acc: 0.7600\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.7472 - val_acc: 0.7400\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.7832 - val_acc: 0.7700\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8616 - val_acc: 0.7600\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8179 - val_acc: 0.7700\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.7600\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8435 - val_acc: 0.7700\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8694 - val_acc: 0.7700\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8729 - val_acc: 0.7700\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8991 - val_acc: 0.7600\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.7600\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9503 - val_acc: 0.7600\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 9.3305e-04 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.7700\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 8.1995e-04 - acc: 1.0000 - val_loss: 0.9445 - val_acc: 0.7600\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 7.5133e-04 - acc: 1.0000 - val_loss: 0.9512 - val_acc: 0.7600\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 6.7344e-04 - acc: 1.0000 - val_loss: 0.9372 - val_acc: 0.7700\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 6.1401e-04 - acc: 1.0000 - val_loss: 0.9871 - val_acc: 0.7600\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 5.7910e-04 - acc: 1.0000 - val_loss: 0.9647 - val_acc: 0.7600\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 5.2063e-04 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.7600\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 4.8418e-04 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.7600\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 4.5582e-04 - acc: 1.0000 - val_loss: 0.9707 - val_acc: 0.7700\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 4.1529e-04 - acc: 1.0000 - val_loss: 0.9780 - val_acc: 0.7700\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 3.8502e-04 - acc: 1.0000 - val_loss: 1.0035 - val_acc: 0.7600\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 7s 270ms/step - loss: 3.5864e-04 - acc: 1.0000 - val_loss: 0.9986 - val_acc: 0.7600\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 3.3920e-04 - acc: 1.0000 - val_loss: 1.0060 - val_acc: 0.7700\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 3.2101e-04 - acc: 1.0000 - val_loss: 1.0523 - val_acc: 0.7600\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 2.9683e-04 - acc: 1.0000 - val_loss: 1.0158 - val_acc: 0.7700\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 2.7784e-04 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.7600\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.5978e-04 - acc: 1.0000 - val_loss: 1.0303 - val_acc: 0.7700\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 2.4746e-04 - acc: 1.0000 - val_loss: 1.0213 - val_acc: 0.7700\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 2.3174e-04 - acc: 1.0000 - val_loss: 1.0652 - val_acc: 0.7600\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.2013e-04 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.7600\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.0729e-04 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.7700\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.9950e-04 - acc: 1.0000 - val_loss: 1.0628 - val_acc: 0.7600\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.8602e-04 - acc: 1.0000 - val_loss: 1.0621 - val_acc: 0.7600\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.7791e-04 - acc: 1.0000 - val_loss: 1.0722 - val_acc: 0.7600\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.6861e-04 - acc: 1.0000 - val_loss: 1.0697 - val_acc: 0.7700\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.6152e-04 - acc: 1.0000 - val_loss: 1.0778 - val_acc: 0.7600\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.5606e-04 - acc: 1.0000 - val_loss: 1.0801 - val_acc: 0.7600\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.4681e-04 - acc: 1.0000 - val_loss: 1.0875 - val_acc: 0.7600\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.3975e-04 - acc: 1.0000 - val_loss: 1.0962 - val_acc: 0.7600\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.3643e-04 - acc: 1.0000 - val_loss: 1.0876 - val_acc: 0.7700\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.3214e-04 - acc: 1.0000 - val_loss: 1.1157 - val_acc: 0.7600\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.2388e-04 - acc: 1.0000 - val_loss: 1.1104 - val_acc: 0.7600\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.1862e-04 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.7700\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.1260e-04 - acc: 1.0000 - val_loss: 1.1155 - val_acc: 0.7600\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.0775e-04 - acc: 1.0000 - val_loss: 1.1239 - val_acc: 0.7600\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.0407e-04 - acc: 1.0000 - val_loss: 1.1086 - val_acc: 0.7700\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.0015e-04 - acc: 1.0000 - val_loss: 1.1271 - val_acc: 0.7600\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 9.5747e-05 - acc: 1.0000 - val_loss: 1.1291 - val_acc: 0.7600\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 9.2216e-05 - acc: 1.0000 - val_loss: 1.1337 - val_acc: 0.7600\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 8.8845e-05 - acc: 1.0000 - val_loss: 1.1444 - val_acc: 0.7600\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 8.5391e-05 - acc: 1.0000 - val_loss: 1.1486 - val_acc: 0.7600\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 8.1605e-05 - acc: 1.0000 - val_loss: 1.1408 - val_acc: 0.7600\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 7.9247e-05 - acc: 1.0000 - val_loss: 1.1543 - val_acc: 0.7600\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 7.5696e-05 - acc: 1.0000 - val_loss: 1.1487 - val_acc: 0.7600\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 7.3226e-05 - acc: 1.0000 - val_loss: 1.1678 - val_acc: 0.7600\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 6.9992e-05 - acc: 1.0000 - val_loss: 1.1605 - val_acc: 0.7600\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 6.6218e-05 - acc: 1.0000 - val_loss: 1.1700 - val_acc: 0.7600\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 6.2528e-05 - acc: 1.0000 - val_loss: 1.1805 - val_acc: 0.7600\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 5.8081e-05 - acc: 1.0000 - val_loss: 1.1786 - val_acc: 0.7600\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 5.4102e-05 - acc: 1.0000 - val_loss: 1.1921 - val_acc: 0.7600\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 4.9934e-05 - acc: 1.0000 - val_loss: 1.1992 - val_acc: 0.7600\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 4.6293e-05 - acc: 1.0000 - val_loss: 1.2174 - val_acc: 0.7600\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 4.3215e-05 - acc: 1.0000 - val_loss: 1.2203 - val_acc: 0.7600\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 4.0603e-05 - acc: 1.0000 - val_loss: 1.2230 - val_acc: 0.7600\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 7s 281ms/step - loss: 3.8384e-05 - acc: 1.0000 - val_loss: 1.2319 - val_acc: 0.7600\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 3.6690e-05 - acc: 1.0000 - val_loss: 1.2362 - val_acc: 0.7600\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 3.5216e-05 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.7600\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 3.3922e-05 - acc: 1.0000 - val_loss: 1.2427 - val_acc: 0.7600\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 3.2808e-05 - acc: 1.0000 - val_loss: 1.2483 - val_acc: 0.7600\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 3.1530e-05 - acc: 1.0000 - val_loss: 1.2467 - val_acc: 0.7700\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 3.0576e-05 - acc: 1.0000 - val_loss: 1.2552 - val_acc: 0.7600\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.9381e-05 - acc: 1.0000 - val_loss: 1.2492 - val_acc: 0.7700\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 2.8250e-05 - acc: 1.0000 - val_loss: 1.2661 - val_acc: 0.7600\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 2.7366e-05 - acc: 1.0000 - val_loss: 1.2669 - val_acc: 0.7600\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 2.6434e-05 - acc: 1.0000 - val_loss: 1.2679 - val_acc: 0.7600\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.5646e-05 - acc: 1.0000 - val_loss: 1.2689 - val_acc: 0.7600\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 2.4721e-05 - acc: 1.0000 - val_loss: 1.2754 - val_acc: 0.7600\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 2.3996e-05 - acc: 1.0000 - val_loss: 1.2774 - val_acc: 0.7600\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 7s 280ms/step - loss: 2.3309e-05 - acc: 1.0000 - val_loss: 1.2803 - val_acc: 0.7600\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.2461e-05 - acc: 1.0000 - val_loss: 1.2839 - val_acc: 0.7600\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 2.1814e-05 - acc: 1.0000 - val_loss: 1.2880 - val_acc: 0.7600\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 2.1102e-05 - acc: 1.0000 - val_loss: 1.2956 - val_acc: 0.7600\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 2.0485e-05 - acc: 1.0000 - val_loss: 1.2943 - val_acc: 0.7600\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 7s 271ms/step - loss: 1.9771e-05 - acc: 1.0000 - val_loss: 1.2983 - val_acc: 0.7600\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.9177e-05 - acc: 1.0000 - val_loss: 1.2979 - val_acc: 0.7600\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.8684e-05 - acc: 1.0000 - val_loss: 1.3019 - val_acc: 0.7600\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 7s 278ms/step - loss: 1.8065e-05 - acc: 1.0000 - val_loss: 1.3044 - val_acc: 0.7600\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 7s 273ms/step - loss: 1.7514e-05 - acc: 1.0000 - val_loss: 1.3090 - val_acc: 0.7600\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.6974e-05 - acc: 1.0000 - val_loss: 1.3113 - val_acc: 0.7600\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 7s 272ms/step - loss: 1.6498e-05 - acc: 1.0000 - val_loss: 1.3160 - val_acc: 0.7600\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 7s 279ms/step - loss: 1.6009e-05 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.7600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "QpwXFpfMzaSA",
        "outputId": "73fc80ee-b6c2-4eb1-83b2-e7ebc20f8c35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7p5zN9yzewh",
        "outputId": "078a5cde-e120-4ded-c10e-93a3e990a8a2"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "## Test Accuracy\n",
        "predictions = model.predict(test_X)\n",
        "ypred = predictions > 0.5\n",
        "test_acc = accuracy_score(test_y, ypred)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "precision, recall, f1score, _ = precision_recall_fscore_support(test_y, ypred, average='binary')\n",
        "\n",
        "auc = roc_auc_score(test_y, ypred)\n",
        "\n",
        "print(\"Train Accuracy:\\t\", acc[-1])\n",
        "print(\"Val Accuracy:\\t\", val_acc[-1])\n",
        "print(\"Test Accuracy:\\t\", test_acc)\n",
        "print(\"Precision:\\t\", precision)\n",
        "print(\"Recall:\\t\\t\", recall)\n",
        "print(\"F1 Score:\\t\", f1score)\n",
        "print(\"AUC:\\t\\t\", auc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:\t 1.0\n",
            "Val Accuracy:\t 0.7599999904632568\n",
            "Test Accuracy:\t 0.8333333333333334\n",
            "Precision:\t 0.82\n",
            "Recall:\t\t 0.8541666666666666\n",
            "F1 Score:\t 0.836734693877551\n",
            "AUC:\t\t 0.8333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hpQ-n8hg5wh",
        "outputId": "b25f9faf-0075-4c05-e59d-1eaa54e5f9e8"
      },
      "source": [
        "model_resnet = ResNet50(include_top=True, weights=None,input_shape =None, classes = 1)\n",
        "model_resnet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1)            2049        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,589,761\n",
            "Trainable params: 23,536,641\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud8QVGANheU7"
      },
      "source": [
        "model_resnet.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NsL-jbviI6L",
        "outputId": "343b0d78-fd1b-4564-d1cc-4df1b46158e0"
      },
      "source": [
        "history = model_resnet.fit(train_X, train_y,\n",
        "                              batch_size=20,\n",
        "                              epochs=100, \n",
        "                              validation_data=(val_X, val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 24s 579ms/step - loss: 1.3388 - acc: 0.5000 - val_loss: 0.8148 - val_acc: 0.5000\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 14s 555ms/step - loss: 0.6307 - acc: 0.5000 - val_loss: 0.8864 - val_acc: 0.5000\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.5570 - acc: 0.5000 - val_loss: 0.9190 - val_acc: 0.5000\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.6905 - acc: 0.5000 - val_loss: 0.7167 - val_acc: 0.5000\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.5789 - acc: 0.5000 - val_loss: 0.8554 - val_acc: 0.5000\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.5125 - acc: 0.5000 - val_loss: 0.9033 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.4371 - acc: 0.5000 - val_loss: 0.7938 - val_acc: 0.5000\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.4317 - acc: 0.5000 - val_loss: 1.0960 - val_acc: 0.5000\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.4414 - acc: 0.5000 - val_loss: 1.1652 - val_acc: 0.5000\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.3492 - acc: 0.5000 - val_loss: 1.7603 - val_acc: 0.5000\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.2874 - acc: 0.5000 - val_loss: 1.2877 - val_acc: 0.5000\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.3072 - acc: 0.5000 - val_loss: 1.1024 - val_acc: 0.5000\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.1959 - acc: 0.5000 - val_loss: 1.2550 - val_acc: 0.5000\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.2180 - acc: 0.5000 - val_loss: 1.1816 - val_acc: 0.5000\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.1542 - acc: 0.5000 - val_loss: 1.8975 - val_acc: 0.5000\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.1587 - acc: 0.5000 - val_loss: 2.2510 - val_acc: 0.5000\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.1721 - acc: 0.5000 - val_loss: 2.1307 - val_acc: 0.5000\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.1649 - acc: 0.5000 - val_loss: 2.2293 - val_acc: 0.5000\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.1149 - acc: 0.5000 - val_loss: 3.8895 - val_acc: 0.5000\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0926 - acc: 0.5000 - val_loss: 2.8862 - val_acc: 0.5000\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0930 - acc: 0.5000 - val_loss: 2.2635 - val_acc: 0.5000\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.1806 - acc: 0.5000 - val_loss: 2.4426 - val_acc: 0.5000\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.1115 - acc: 0.5000 - val_loss: 5.0273 - val_acc: 0.5000\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0684 - acc: 0.5000 - val_loss: 3.4029 - val_acc: 0.5000\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0471 - acc: 0.5000 - val_loss: 3.6565 - val_acc: 0.5000\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0419 - acc: 0.5000 - val_loss: 2.5724 - val_acc: 0.5000\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0323 - acc: 0.5000 - val_loss: 3.2022 - val_acc: 0.5000\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0253 - acc: 0.5000 - val_loss: 2.5545 - val_acc: 0.5000\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0819 - acc: 0.5000 - val_loss: 1.8998 - val_acc: 0.5000\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0292 - acc: 0.5000 - val_loss: 2.7837 - val_acc: 0.5000\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0266 - acc: 0.5000 - val_loss: 2.1796 - val_acc: 0.5000\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0135 - acc: 0.5000 - val_loss: 2.1923 - val_acc: 0.5000\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.0115 - acc: 0.5000 - val_loss: 1.8501 - val_acc: 0.5000\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0047 - acc: 0.5000 - val_loss: 1.7255 - val_acc: 0.5000\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.0227 - acc: 0.5000 - val_loss: 2.1895 - val_acc: 0.5000\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0341 - acc: 0.5000 - val_loss: 3.6193 - val_acc: 0.5000\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0749 - acc: 0.5000 - val_loss: 2.0945 - val_acc: 0.5000\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.1626 - acc: 0.5000 - val_loss: 5.9423 - val_acc: 0.5000\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.1685 - acc: 0.5000 - val_loss: 22.8414 - val_acc: 0.5000\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.1764 - acc: 0.5000 - val_loss: 5.0100 - val_acc: 0.5000\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0679 - acc: 0.5000 - val_loss: 2.0708 - val_acc: 0.5000\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0388 - acc: 0.5000 - val_loss: 2.7455 - val_acc: 0.5000\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0142 - acc: 0.5000 - val_loss: 2.7766 - val_acc: 0.5000\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.0029 - acc: 0.5000 - val_loss: 2.4202 - val_acc: 0.5000\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0050 - acc: 0.5000 - val_loss: 2.2497 - val_acc: 0.5000\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.0247 - acc: 0.5000 - val_loss: 2.1140 - val_acc: 0.5000\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.0665 - acc: 0.5000 - val_loss: 1.9438 - val_acc: 0.5000\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0584 - acc: 0.5000 - val_loss: 1.8591 - val_acc: 0.5000\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0744 - acc: 0.5000 - val_loss: 3.6652 - val_acc: 0.5000\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.1495 - acc: 0.5000 - val_loss: 3.3432 - val_acc: 0.5000\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.1184 - acc: 0.5000 - val_loss: 2.1188 - val_acc: 0.5000\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0866 - acc: 0.5000 - val_loss: 2.8906 - val_acc: 0.5000\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.0428 - acc: 0.5000 - val_loss: 3.4272 - val_acc: 0.5000\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0301 - acc: 0.5000 - val_loss: 3.1794 - val_acc: 0.5000\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0437 - acc: 0.5000 - val_loss: 2.3614 - val_acc: 0.5000\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0289 - acc: 0.5000 - val_loss: 2.7530 - val_acc: 0.5000\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.0189 - acc: 0.5000 - val_loss: 2.3035 - val_acc: 0.5000\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0058 - acc: 0.5000 - val_loss: 2.6046 - val_acc: 0.5000\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0112 - acc: 0.5000 - val_loss: 1.9229 - val_acc: 0.5000\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0046 - acc: 0.5000 - val_loss: 1.8031 - val_acc: 0.5000\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.0024 - acc: 0.5000 - val_loss: 2.1425 - val_acc: 0.5000\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 4.4439e-04 - acc: 0.5000 - val_loss: 2.1233 - val_acc: 0.5000\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 7.7051e-04 - acc: 0.5000 - val_loss: 2.0111 - val_acc: 0.5000\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0014 - acc: 0.5000 - val_loss: 1.9297 - val_acc: 0.5000\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 3.0611e-04 - acc: 0.5000 - val_loss: 1.9099 - val_acc: 0.5000\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 1.8806e-04 - acc: 0.5000 - val_loss: 1.9051 - val_acc: 0.5000\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 2.0293e-04 - acc: 0.5000 - val_loss: 1.9113 - val_acc: 0.5000\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 1.4963e-04 - acc: 0.5000 - val_loss: 1.9389 - val_acc: 0.5000\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0057 - acc: 0.5000 - val_loss: 1.9839 - val_acc: 0.5000\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.0090 - acc: 0.5000 - val_loss: 1.7760 - val_acc: 0.5000\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.0709 - acc: 0.5000 - val_loss: 2.9704 - val_acc: 0.5000\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.1452 - acc: 0.5000 - val_loss: 22.5856 - val_acc: 0.5000\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0478 - acc: 0.5000 - val_loss: 5.4141 - val_acc: 0.5000\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.0721 - acc: 0.5000 - val_loss: 3.6345 - val_acc: 0.5000\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.0413 - acc: 0.5000 - val_loss: 2.4560 - val_acc: 0.5000\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0437 - acc: 0.5000 - val_loss: 7.1462 - val_acc: 0.5000\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0566 - acc: 0.5000 - val_loss: 3.6961 - val_acc: 0.5000\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0362 - acc: 0.5000 - val_loss: 3.1292 - val_acc: 0.5000\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0060 - acc: 0.5000 - val_loss: 2.8262 - val_acc: 0.5000\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0046 - acc: 0.5000 - val_loss: 4.2215 - val_acc: 0.5000\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0016 - acc: 0.5000 - val_loss: 3.0346 - val_acc: 0.5000\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0017 - acc: 0.5000 - val_loss: 2.3999 - val_acc: 0.5000\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0080 - acc: 0.5000 - val_loss: 2.0618 - val_acc: 0.5000\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.0073 - acc: 0.5000 - val_loss: 2.0325 - val_acc: 0.5000\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0031 - acc: 0.5000 - val_loss: 2.2752 - val_acc: 0.5000\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0092 - acc: 0.5000 - val_loss: 2.1873 - val_acc: 0.5000\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 14s 552ms/step - loss: 0.0262 - acc: 0.5000 - val_loss: 7.1538 - val_acc: 0.5000\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.0458 - acc: 0.5000 - val_loss: 8.8759 - val_acc: 0.5000\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.1477 - acc: 0.5000 - val_loss: 2.8316 - val_acc: 0.5000\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.1840 - acc: 0.5000 - val_loss: 3.1625 - val_acc: 0.5000\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 14s 551ms/step - loss: 0.1969 - acc: 0.5000 - val_loss: 8.6752 - val_acc: 0.5000\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.1983 - acc: 0.5000 - val_loss: 103.0618 - val_acc: 0.5000\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.1345 - acc: 0.5000 - val_loss: 4.5507 - val_acc: 0.5000\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 13s 531ms/step - loss: 0.0307 - acc: 0.5000 - val_loss: 4.1465 - val_acc: 0.5000\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0082 - acc: 0.5000 - val_loss: 1.9514 - val_acc: 0.5000\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 0.0060 - acc: 0.5000 - val_loss: 2.0488 - val_acc: 0.5000\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 0.0016 - acc: 0.5000 - val_loss: 2.0193 - val_acc: 0.5000\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0025 - acc: 0.5000 - val_loss: 2.0509 - val_acc: 0.5000\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.0011 - acc: 0.5000 - val_loss: 2.1029 - val_acc: 0.5000\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 13s 532ms/step - loss: 6.8837e-04 - acc: 0.5000 - val_loss: 2.1268 - val_acc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "44izxGHIksSd",
        "outputId": "7059e174-ec9b-473a-9fbc-ae4d3a3e7425"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B68K-Sksk40k",
        "outputId": "73985168-dec3-437f-bed4-9730f0d14089"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "## Test Accuracy\n",
        "predictions = model.predict(test_X)\n",
        "ypred = predictions > 0.5\n",
        "test_acc = accuracy_score(test_y, ypred)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "precision, recall, f1score, _ = precision_recall_fscore_support(test_y, ypred, average='binary')\n",
        "\n",
        "auc = roc_auc_score(test_y, ypred)\n",
        "\n",
        "print(\"Train Accuracy:\\t\", acc[-1])\n",
        "print(\"Val Accuracy:\\t\", val_acc[-1])\n",
        "print(\"Test Accuracy:\\t\", test_acc)\n",
        "print(\"Precision:\\t\", precision)\n",
        "print(\"Recall:\\t\\t\", recall)\n",
        "print(\"F1 Score:\\t\", f1score)\n",
        "print(\"AUC:\\t\\t\", auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy:\t 0.5\n",
            "Val Accuracy:\t 0.5\n",
            "Test Accuracy:\t 0.8333333333333334\n",
            "Precision:\t 0.82\n",
            "Recall:\t\t 0.8541666666666666\n",
            "F1 Score:\t 0.836734693877551\n",
            "AUC:\t\t 0.8333333333333333\n"
          ]
        }
      ]
    }
  ]
}